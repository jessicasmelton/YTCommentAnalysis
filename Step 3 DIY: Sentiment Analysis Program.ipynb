{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8WRcg2XOQUtbjkAcVnk4J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessicasmelton/YTCommentAnalysis/blob/main/Step%203%3A%20Sentiment%20Analysis%20Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis Program for YouTube Comments:**\n",
        "\n",
        "This program performs sentiment analysis on YouTube comments. It filters comments based on a specific set of keywords and emojis relevant to the topic, then analyzes the sentiment of the filtered comments using TextBlob. The sentiment analysis results, including sentiment distribution and trends over time, are visualized and saved to a new CSV file.\n",
        "\n",
        "---\n",
        "\n",
        "**Usage**\n",
        "\n",
        "* Ensure your CSV file containing the cleaned and translated comments is correctly formatted and saved in the specified location. This file should be the output from the previous data cleaning and translation steps.\n",
        "\n",
        "* Replace the file_path variable value in the code with the path to your CSV file. Make sure the file path is correctly specified to avoid file not found errors.\n",
        "\n",
        "* Create an extensive keyword list specific to your topic. This list is crucial for filtering relevant comments. It is recommended to use a minimum of 150 keywords.\n",
        "\n",
        "* Execute the program in a Python environment such as Google Colab, Jupyter Notebook, or any local Python environment.\n",
        "\n",
        "* The program will read the CSV file, filter comments based on the keyword list, perform sentiment analysis, and save the results to a new CSV file.\n",
        "\n",
        "---\n",
        "\n",
        "**Notes**\n",
        "\n",
        "* The keyword list is essential for filtering relevant comments. Customize the keywords list in the code to match your specific research topic.\n",
        "\n",
        "* The program includes a basic dictionary for emoji sentiment. Expand or modify the emoji_sentiment_dict as needed for your analysis.\n",
        "\n",
        "* The sentiment analysis is conducted using TextBlob, which provides polarity (positive/negative) and subjectivity (objective/subjective) scores for each comment.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Potential Errors and Fixes**\n",
        "\n",
        "* Ensure the file path to the CSV file is correct. Verify that the file exists at the specified location.\n",
        "\n",
        "* If the filtering does not work as expected, ensure the keywords are correctly defined and relevant to your topic. Regular expressions are used for matching, so check for any syntax errors.\n",
        "\n",
        "* If there are issues with saving the CSV file, check for special characters in the file path or name that may cause problems. Ensure the directory where the file is being saved exists and is writable."
      ],
      "metadata": {
        "id": "tDKF8ef3tS-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "!pip install emoji"
      ],
      "metadata": {
        "id": "4tT0i3-TuWtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis Program\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd  # Library for data manipulation and analysis\n",
        "import numpy as np  # Library for numerical operations\n",
        "from textblob import TextBlob  # Library for text processing and sentiment analysis\n",
        "import matplotlib.pyplot as plt  # Library for plotting data\n",
        "import re  # Regular expressions library for text cleaning\n",
        "import emoji  # Library for handling emojis\n",
        "\n",
        "# Load the cleaned and translated comments CSV file\n",
        "file_path = 'INSERT YOUR FILE PATH HERE.csv'  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define the keywords for filtering relevant comments\n",
        "# Note: It is important to create an extensive keyword list specific to your topic.\n",
        "keywords = [\n",
        "    # ... (your extensive keyword list)\n",
        "]\n",
        "\n",
        "# Define the emoji sentiment dictionary\n",
        "emoji_sentiment_dict = {\n",
        "    # Mapping of emojis to sentiment categories\n",
        "    \"❤️\": \"positive\", \"💩\": \"negative\", \"😍\": \"positive\",\n",
        "    \"😊\": \"positive\", \"😢\": \"negative\", \"😡\": \"negative\", \"👍\": \"positive\",\n",
        "    \"👎\": \"negative\", \"🎉\": \"positive\", \"🙌\": \"positive\", \"😞\": \"negative\",\n",
        "    \"😭\": \"negative\", \"😃\": \"positive\", \"😔\": \"negative\", \"🤔\": \"neutral\",\n",
        "    \"😐\": \"neutral\", \"🙄\": \"negative\", \"😤\": \"negative\", \"😉\": \"positive\",\n",
        "    \"😁\": \"positive\", \"😠\": \"negative\", \"😩\": \"negative\", \"😅\": \"positive\",\n",
        "    \"🤢\": \"negative\", \"🤮\": \"negative\", \"🥳\": \"positive\", \"😎\": \"positive\",\n",
        "    \"🤯\": \"negative\", \"😇\": \"positive\", \"😈\": \"negative\", \"👿\": \"negative\",\n",
        "    \"🇬🇾\": \"neutral\",  # Guyana flag\n",
        "    \"🇻🇪\": \"neutral\"   # Venezuela flag\n",
        "}\n",
        "\n",
        "# Function to extract emojis from text\n",
        "def extract_emojis(text):\n",
        "    return ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
        "\n",
        "# Function to determine if a comment should be included based on emojis and text\n",
        "def should_include_comment_based_on_emojis(comment):\n",
        "    emojis_in_comment = extract_emojis(comment)\n",
        "\n",
        "    # Include if it has a national flag and another emoji\n",
        "    if \"🇬🇾\" in emojis_in_comment or \"🇻🇪\" in emojis_in_comment:\n",
        "        if len(emojis_in_comment) > 1:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Function to filter relevant comments based on keywords and emojis\n",
        "def filter_comments(comment):\n",
        "    comment_lower = comment.lower()  # Convert comment to lowercase\n",
        "\n",
        "    # Include if there's relevant text (keywords)\n",
        "    for keyword in keywords:\n",
        "        if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', comment_lower):\n",
        "            return True\n",
        "\n",
        "    # Include based on emoji criteria\n",
        "    if should_include_comment_based_on_emojis(comment):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# Apply the filter to determine relevance of comments\n",
        "df['Relevant'] = df['Comment Text'].apply(filter_comments)\n",
        "filtered_df = df[df['Relevant']]\n",
        "\n",
        "# Function to conduct sentiment analysis on comments\n",
        "def get_sentiment(comment):\n",
        "    blob = TextBlob(comment)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "# Apply sentiment analysis to relevant comments\n",
        "filtered_df[['Polarity', 'Subjectivity']] = filtered_df['Comment Text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
        "\n",
        "# Function to categorize sentiment based on polarity\n",
        "def sentiment_category(polarity):\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Categorize sentiment for each comment\n",
        "filtered_df['Sentiment'] = filtered_df['Polarity'].apply(sentiment_category)\n",
        "\n",
        "# Calculate the proportion of comments that are positive, negative, or neutral\n",
        "sentiment_counts = filtered_df['Sentiment'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Sentiment Proportions:\")\n",
        "print(sentiment_counts)\n",
        "\n",
        "# Track sentiment over time by month\n",
        "filtered_df['Date Published'] = pd.to_datetime(filtered_df['Date Published'])\n",
        "filtered_df['Month'] = filtered_df['Date Published'].dt.to_period('M')\n",
        "monthly_sentiment = filtered_df.groupby('Month')['Polarity'].mean()\n",
        "\n",
        "# Visualize the results\n",
        "# Sentiment Distribution Bar Chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sentiment_counts.plot(kind='bar', color=['green', 'gray', 'red'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Proportion (%)')\n",
        "plt.show()\n",
        "\n",
        "# Sentiment Over Time Line Chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "monthly_sentiment.plot(kind='line', marker='o')\n",
        "plt.title('Sentiment Over Time')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Polarity')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save the filtered and analyzed data to a new CSV file\n",
        "output_file_path = 'Total_Sentiment_Analysis.csv'\n",
        "filtered_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Filtered and analyzed data has been saved to {output_file_path}\")"
      ],
      "metadata": {
        "id": "7AGd9FfEufUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
